{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b37cb3d9-93aa-4743-9a97-27ff092638d3",
   "metadata": {},
   "source": [
    "**First We need to initiate our SparkSession and find its path**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14530df1-f356-44e8-9230-2c8fb8e52aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "129610b7-bdd2-4c74-a45c-8ce1c5315370",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4997c834-e9f6-4ac2-8407-3912e657404a",
   "metadata": {},
   "source": [
    "**Building a spark instance as our sparksession:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f483fda3-7740-4d0e-8725-e219050d9c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c951b1f-886f-49a3-95a4-e039ed4eb7c5",
   "metadata": {},
   "source": [
    "**Reading the file into a dataframe through our spark**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd753427-c080-48cf-a288-fb0e71bd1486",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format('json').load('Book_Exercises\\data\\json\\summer 2015.json')\n",
    "# Creating a SQLtable from our DataFrame\n",
    "df.createOrReplaceTempView('dftable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ac1a4418-7503-4e44-9de8-bd2816c188bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|       United States|            Romania|   15|\n",
      "|       United States|            Croatia|    1|\n",
      "|       United States|            Ireland|  344|\n",
      "|               Egypt|      United States|   15|\n",
      "|       United States|              India|   62|\n",
      "|       United States|          Singapore|    1|\n",
      "|       United States|            Grenada|   62|\n",
      "|          Costa Rica|      United States|  588|\n",
      "|             Senegal|      United States|   40|\n",
      "|             Moldova|      United States|    1|\n",
      "|       United States|       Sint Maarten|  325|\n",
      "|       United States|   Marshall Islands|   39|\n",
      "|              Guyana|      United States|   64|\n",
      "|               Malta|      United States|    1|\n",
      "|            Anguilla|      United States|   41|\n",
      "|             Bolivia|      United States|   30|\n",
      "|       United States|           Paraguay|    6|\n",
      "|             Algeria|      United States|    4|\n",
      "|Turks and Caicos ...|      United States|  230|\n",
      "|       United States|          Gibraltar|    1|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8cf9a42-237a-4492-89a8-cdc0fcba0e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Romania', count=15),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Croatia', count=1),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Ireland', count=344)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ac22592-8e76-46cb-98b7-6b6354e6c44a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string, count: bigint]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0653442d-b4d0-491a-8856-8fafae2360c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DEST_COUNTRY_NAME: string (nullable = true)\n",
      " |-- ORIGIN_COUNTRY_NAME: string (nullable = true)\n",
      " |-- count: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dda8d7bb-4dc9-4e64-9605-d90a19bb7f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(DEST_COUNTRY_NAME,StringType,true),StructField(ORIGIN_COUNTRY_NAME,StringType,true),StructField(count,LongType,true)))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a5e6700-7da5-4b54-a6d3-74ead4aad998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DEST_COUNTRY_NAME', 'ORIGIN_COUNTRY_NAME', 'count']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebe66e2-a64f-4f3a-8532-1d5e0d397b4a",
   "metadata": {},
   "source": [
    "**Columns and Expressions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdde025c-be76-431c-b225-c7814434c842",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7b799f9e-53e5-4ddd-8df6-86aa6807fb7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'Name'>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Constructiong a col but it has no data/rows inside\n",
    "col('Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "df4367d8-6a6f-4697-83cf-e4256c3ee24a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'DEST_COUNTRY_NAME'>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we resolve a column out of a specific dataframe\n",
    "# in scala it's df.col('DEST_COUNTRY_NAME')\n",
    "\n",
    "# in python\n",
    "df['DEST_COUNTRY_NAME']\n",
    "#df.DEST_COUNTRY_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6d93d18e-de5b-4faf-a696-efb788d7252c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column<'((count - 5) > count)'>\n",
      "Column<'((count * 5) > count)'>\n"
     ]
    }
   ],
   "source": [
    "# note how columns are expressions\n",
    "print((df['count'] - 5) > df['count'])\n",
    "print(expr('(count*5) > count'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c81f291-6c54-4d4a-a8de-01d9d9eabc48",
   "metadata": {},
   "source": [
    "**Rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "10d01d6c-bbe6-448f-85cf-9c920b42319c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Romania', count=15)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "42bb2794-9301-4882-b58c-d6d658888400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Row('Hello', None, 1, False)>\n",
      "Hello\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "myRow= Row(\"Hello\", None, 1, False)\n",
    "print(myRow)\n",
    "print(myRow[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427bcc64-d4fe-4cce-a069-b381ee833790",
   "metadata": {},
   "source": [
    "**DataFrames**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4b5448fd-8a4c-4104-a458-ef5e09540155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-----+\n",
      "| some| col|names|\n",
      "+-----+----+-----+\n",
      "|Hello|null|    1|\n",
      "+-----+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Creating a DataFrame Manually\n",
    "\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import StructField, StructType, StringType, LongType\n",
    "myManualSchema = StructType([\n",
    "StructField(\"some\", StringType(), True),\n",
    "StructField(\"col\", StringType(), True),\n",
    "StructField(\"names\", LongType(), False)\n",
    "])\n",
    "myRow = Row(\"Hello\", None, 1)\n",
    "myDf = spark.createDataFrame([myRow], myManualSchema)\n",
    "myDf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd88022-cd1c-4720-ae84-369b002726c2",
   "metadata": {},
   "source": [
    "---\n",
    "**select and selectExpr**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "290ecc0c-8bcc-46ad-bca6-e2c888c0e3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------+-----------------+\n",
      "|DEST_COUNTRY_NAME|DEST_COUNTRY_NAME|DEST_COUNTRY_NAME|\n",
      "+-----------------+-----------------+-----------------+\n",
      "|    United States|    United States|    United States|\n",
      "|    United States|    United States|    United States|\n",
      "+-----------------+-----------------+-----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr, col, column\n",
    "df.select(\n",
    "expr(\"DEST_COUNTRY_NAME\"),\n",
    "col(\"DEST_COUNTRY_NAME\"),\n",
    "\"DEST_COUNTRY_NAME\")\\\n",
    ".show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1d6319ff-9e3e-4603-ba1d-18fe7a273870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|         DEST|\n",
      "+-------------+\n",
      "|United States|\n",
      "|United States|\n",
      "+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(expr(\"DEST_COUNTRY_NAME AS DEST\")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d416f9a1-4e6e-4cf0-80b0-c82a32144634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|         dest|\n",
      "+-------------+\n",
      "|United States|\n",
      "|United States|\n",
      "|United States|\n",
      "|        Egypt|\n",
      "+-------------+\n",
      "only showing top 4 rows\n",
      "\n",
      "+-----------------+-------------------+-----+-------------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|withinCountry|\n",
      "+-----------------+-------------------+-----+-------------+\n",
      "|    United States|            Romania|   15|        false|\n",
      "|    United States|            Croatia|    1|        false|\n",
      "+-----------------+-------------------+-----+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.selectExpr('DEST_COUNTRY_NAME as dest').show(4)\n",
    "\n",
    "df.selectExpr(\n",
    "\"*\", # all original columns\n",
    "\"(DEST_COUNTRY_NAME = ORIGIN_COUNTRY_NAME) as withinCountry\")\\\n",
    ".show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f864fa-9907-4598-80bd-61c12a0f62ed",
   "metadata": {},
   "source": [
    "---\n",
    "**Aggregation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dce44095-d88f-4ced-9e96-3bcb74cefa64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+-----------+\n",
      "|   sum|count|        avg|\n",
      "+------+-----+-----------+\n",
      "|453316|  256|1770.765625|\n",
      "+------+-----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.selectExpr('sum(count) as sum', 'count(count) as count', 'avg(count) as avg').show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4846672b-c258-48ab-a009-a47b7dc70aa0",
   "metadata": {},
   "source": [
    "---\n",
    "**Literals** \\\n",
    "Sometimes, we need to pass explicit values into Spark that are just a value (rather than a new\n",
    "column). This might be a constant value or something we’ll need to compare to later on. The\n",
    "way we do this is through literals. This is basically a translation from a given programming\n",
    "language’s literal value to one that Spark understands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "83b5e601-477c-40f9-8207-548d45187772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+---+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|One|\n",
      "+-----------------+-------------------+-----+---+\n",
      "|    United States|            Romania|   15|  1|\n",
      "|    United States|            Croatia|    1|  1|\n",
      "+-----------------+-------------------+-----+---+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "df.select(expr('*'), lit(1).alias('One')).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b140f0d-7cd1-4a2c-b168-e9be0366a22e",
   "metadata": {},
   "source": [
    "---\n",
    "**Adding Columns** \\\n",
    "Another more formal way of adding a new column to a DataFrame, and that’s by using the\n",
    "withColumn method on our DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e8e729d7-3dfb-4dc0-847d-2d6266a9eb6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|   15|\n",
      "|    United States|            Croatia|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n",
      "+-----------------+-------------------+-----+---------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|NUmberone|\n",
      "+-----------------+-------------------+-----+---------+\n",
      "|    United States|            Romania|   15|        1|\n",
      "|    United States|            Croatia|    1|        1|\n",
      "+-----------------+-------------------+-----+---------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|   15|\n",
      "|    United States|            Croatia|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(2)\n",
    "df.withColumn('NUmberone', lit(1)).show(2)\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ee1c7c-b560-4deb-8126-54326f1c0871",
   "metadata": {},
   "source": [
    "---\n",
    "**Renaming a column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bd9f4ece-fb56-4667-92fe-bdde6e239251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------------+-----+\n",
      "|         dest|ORIGIN_COUNTRY_NAME|count|\n",
      "+-------------+-------------------+-----+\n",
      "|United States|            Romania|   15|\n",
      "|United States|            Croatia|    1|\n",
      "+-------------+-------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n",
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|   15|\n",
      "|    United States|            Croatia|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumnRenamed('DEST_COUNTRY_NAME', 'dest').show(2)\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e789e97-f89a-4208-abbd-d9848816ef8c",
   "metadata": {},
   "source": [
    "---\n",
    "**Reserved Characters and Keywords** \\\n",
    "Handling reserved characters like spaces or dashes in column means escaping column names appropriately. In Spark, we do this by\n",
    "using backtick (`) character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "23d85df9-af6a-4241-96e3-09258bd1d626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+-----------------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|The New long-name|\n",
      "+-----------------+-------------------+-----+-----------------+\n",
      "|    United States|            Romania|   15|               15|\n",
      "|    United States|            Croatia|    1|                1|\n",
      "+-----------------+-------------------+-----+-----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testColumn = df.withColumn('The New long-name', col('count')) #.show(2) gives nonetype\n",
    "testColumn.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b5e3d4-38d0-4579-bed4-07f9abec7ce6",
   "metadata": {},
   "source": [
    "**We don’t need escape characters here because the first argument to withColumn is just a string \\\n",
    "for the new column name. In this example, however, we need to use backticks because we’re \\\n",
    "referencing a column in an expression:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "82e47cdd-8637-48bd-b540-7c9173ee480e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---+\n",
      "|The New long-Name|col|\n",
      "+-----------------+---+\n",
      "|               15| 15|\n",
      "|                1|  1|\n",
      "+-----------------+---+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testColumn.selectExpr('`The New long-Name`', '`The New long-Name` as col').show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd2d9c7-d429-4adc-9e6e-78e04b159ba7",
   "metadata": {},
   "source": [
    "**We can refer to columns with reserved characters (and not escape them) if we’re doing an \\\n",
    "explicit string-to-column reference, which is interpreted as a literal instead of an expression.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "423b5432-a3b8-4e05-817f-8aac497e031a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+-----------------+---+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|The New long-name|col|\n",
      "+-----------------+-------------------+-----+-----------------+---+\n",
      "|    United States|            Romania|   15|               15| 15|\n",
      "|    United States|            Croatia|    1|                1|  1|\n",
      "+-----------------+-------------------+-----+-----------------+---+\n",
      "only showing top 2 rows\n",
      "\n",
      "+-----------------+-------------------+-----+-----------------+---+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|The New long-name|col|\n",
      "+-----------------+-------------------+-----+-----------------+---+\n",
      "|    United States|            Romania|   15|               15| 15|\n",
      "|    United States|            Croatia|    1|                1|  1|\n",
      "+-----------------+-------------------+-----+-----------------+---+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testColumn.withColumn( 'col', col('The New long-Name')).show(2)\n",
    "testColumn.withColumn( 'col', expr('`The New long-Name`')).show(2)\n",
    "#testColumn.withColumn( 'col', expr('The New long-Name')).show(2)     # Gives error without `.....`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcef6db9-e39f-4a71-8627-59827e70511c",
   "metadata": {},
   "source": [
    "---\n",
    "**Case Sensitivity** \\\n",
    "By default Spark is $<< case \\ insensitive >>$ ; however, you can make Spark case sensitive by setting the\n",
    "configuration: \\\n",
    "**set spark.sql.caseSensitive true**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9626ea25-e4cf-4150-8213-8eba3d2fbb7f",
   "metadata": {},
   "source": [
    "---\n",
    "**Removing Columns** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "06d75561-8a0c-4c14-99fe-dd8b061f6582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ORIGIN_COUNTRY_NAME', 'count']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('DEST_COUNTRY_NAME').columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc4b7e5-ec98-49da-867d-7894973ff3a9",
   "metadata": {},
   "source": [
    "---\n",
    "**Changing a Column's Type (Casting)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "08f77a64-de56-4bc3-b54d-ba2cfeb18da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DEST_COUNTRY_NAME: string (nullable = true)\n",
      " |-- ORIGIN_COUNTRY_NAME: string (nullable = true)\n",
      " |-- count: long (nullable = true)\n",
      " |-- count2: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('count2', col('count').cast('int')).printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9d1837-0bb5-414d-8a90-95ae16f97f40",
   "metadata": {},
   "source": [
    "---\n",
    "**Filtering Rows** \\\n",
    "To filter rows, we create an expression that evaluates to true or false. We can use $where$ or $filter$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff1a2f5b-5d62-4690-8500-35bab1b3d849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|          Singapore|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df.filter(expr('count > 2')).show(2)\n",
    "# df.filter(col('count') > 2).show(2)\n",
    "#df.filter('count < 2').show(2)\n",
    "#df.where(col('count') > 2).show(2)\n",
    "df.where('count < 2').show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9d9302-dddd-4fcb-9867-112a383287f3",
   "metadata": {},
   "source": [
    "***We can put multiple filters into the same expression. Although this is possible, it is not always useful.\\\n",
    "Because Spark automatically performs all filtering operations at the same time regardless of the filter ordering.\\\n",
    "This means that if you want to specify multiple AND filters, just chain them sequentially and let Spark handle the rest:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "e7304a79-cfee-4c6f-aef4-32a706b5c380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|   15|\n",
      "|    United States|            Ireland|  344|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n",
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|   15|\n",
      "|    United States|            Ireland|  344|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(expr('count > 2')).where(expr('ORIGIN_COUNTRY_NAME != \"Croatia\"')).show(2)\n",
    "\n",
    "# Is better than:\n",
    "df.where(expr('count > 2 and ORIGIN_COUNTRY_NAME != \"Croatia\"')).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f1381c-0ae2-4974-8af6-aba5cb0c7f4d",
   "metadata": {},
   "source": [
    "---\n",
    "**Unique Rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "7f88ea97-0434-4969-86bd-beb1a94f6194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('DEST_COUNTRY_NAME').distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf0b60c-57da-468b-be29-03255396b971",
   "metadata": {},
   "source": [
    "---\n",
    "**Random Samples** \\\n",
    "**The $sample$ method on a DataFrame makes it possible for you to:**\n",
    "* specify a fraction of rows to extract from a DataFrame.\n",
    "* whether you’d like to sample with or without replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "05ea24e1-a406-4e0e-af81-4f64c61ea456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|            Egypt|      United States|   15|\n",
      "|       Costa Rica|      United States|  588|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n",
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|              India|   62|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n",
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|            Egypt|      United States|   15|\n",
      "|    United States|              India|   62|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "withReplacement = False\n",
    "fraction = 0.5\n",
    "df.sample(withReplacement, fraction, seed).show(2)\n",
    "df.sample(withReplacement, fraction).show(2) # Without seed\n",
    "df.sample(withReplacement, fraction).show(2) # Without seed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ec2a4a-9fb4-41a7-8b12-8278bf8f8cfb",
   "metadata": {},
   "source": [
    "---\n",
    "**Random Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "4a7a88ce-10a8-43c7-a70d-9a84245799cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|          Austria|      United States|   62|\n",
      "|           Brazil|      United States|  853|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n",
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|          Algeria|      United States|    4|\n",
      "|           Angola|      United States|   15|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = df.randomSplit([0.25, 0.75], seed)\n",
    "df2[0].show(2)\n",
    "df2[1].show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5295bc43-0a22-402a-9404-674c992cb3d0",
   "metadata": {},
   "source": [
    "---\n",
    "**Concatenating and Appending Rows (Union):** \\\n",
    "DataFrames are immutable.So we cannot append to DataFrames because that would be changing it.\\\n",
    "To append to a DataFrame, union the original DataFrame along with the new DataFrame.\\\n",
    "They should have the same schema and number of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "34ddfd28-a688-4ced-9929-30275fc7bc1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|          Singapore|    1|\n",
      "|    United States|          Gibraltar|    1|\n",
      "|    United States|             Cyprus|    1|\n",
      "|    United States|            Estonia|    1|\n",
      "|    United States|          Lithuania|    1|\n",
      "|    United States|           Bulgaria|    1|\n",
      "|    United States|            Georgia|    1|\n",
      "|    United States|            Bahrain|    1|\n",
      "|    United States|   Papua New Guinea|    1|\n",
      "|    United States|         Montenegro|    1|\n",
      "|    United States|            Namibia|    1|\n",
      "|    New Country 2|    Other Country 3|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# in Python\n",
    "from pyspark.sql import Row\n",
    "schema = df.schema\n",
    "newRows = [\n",
    "Row(\"New Country\", \"Other Country\", 5),\n",
    "Row(\"New Country 2\", \"Other Country 3\", 1)\n",
    "] \n",
    "parallelizedRows = spark.sparkContext.parallelize(newRows)\n",
    "newDF = spark.createDataFrame(parallelizedRows, schema)\n",
    "\n",
    "# in Python\n",
    "df.union(newDF)\\\n",
    ".where(\"count = 1\")\\\n",
    ".where(col(\"ORIGIN_COUNTRY_NAME\") != \"United States\")\\\n",
    ".show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e386c42-25f5-43ff-98b5-4a6949f7dcd5",
   "metadata": {},
   "source": [
    "---\n",
    "**Sorting Rows** \\\n",
    "$sort$ and $orderBy$ that work the exact same way.\\\n",
    "**They accept both column expressions and strings as well as multiple columns. \\\n",
    "The default is to sort in ascending order**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "0304400f-695f-4d07-9edf-73ea74b0e49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|               Malta|      United States|    1|\n",
      "|Saint Vincent and...|      United States|    1|\n",
      "|       United States|            Croatia|    1|\n",
      "|       United States|          Gibraltar|    1|\n",
      "|       United States|          Singapore|    1|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|     Burkina Faso|      United States|    1|\n",
      "|    Cote d'Ivoire|      United States|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sort('count').show(5)\n",
    "df.orderBy(col('count'), expr('DEST_COUNTRY_NAME'), 'ORIGIN_COUNTRY_NAME').show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "01b4779d-2aa4-4154-b780-347de58197a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+\n",
      "|   DEST_COUNTRY_NAME| ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+--------------------+-----+\n",
      "|       United States|              Guyana|   63|\n",
      "|       United States|             Austria|   63|\n",
      "|              Guyana|       United States|   64|\n",
      "|Federated States ...|       United States|   69|\n",
      "|       United States|Federated States ...|   69|\n",
      "+--------------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To specify sorting direction\n",
    "from pyspark.sql.functions import asc, desc\n",
    "df.orderBy(col('count').asc(), col('ORIGIN_COUNTRY_NAME').desc()).where(expr('count > 62')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "e944e140-e22a-4ed5-aa82-a8addd6fc16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|               Malta|      United States|    1|\n",
      "|Saint Vincent and...|      United States|    1|\n",
      "|       United States|            Croatia|    1|\n",
      "|       United States|          Gibraltar|    1|\n",
      "|       United States|          Singapore|    1|\n",
      "|             Moldova|      United States|    1|\n",
      "+--------------------+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(expr(\"count desc\")).limit(6).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3233ba3e-45a9-4f62-a7ef-f7830dc7ed61",
   "metadata": {},
   "source": [
    "---\n",
    "**Repartitioning:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "60a5963a-de64-47db-9c49-a68fb74d4f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "4e29eee3-643b-4d31-acb7-a19069692975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|       United States|            Denmark|  152|\n",
      "|       United States|         Martinique|   43|\n",
      "|       United States|        Saint Lucia|  136|\n",
      "|             Ireland|      United States|  335|\n",
      "|         South Korea|      United States| 1048|\n",
      "|       United States|              Italy|  438|\n",
      "|       United States|             Greece|   23|\n",
      "|Bonaire, Sint Eus...|      United States|   58|\n",
      "|              France|      United States|  935|\n",
      "|       United States|             Cyprus|    1|\n",
      "|       United States|         Montenegro|    1|\n",
      "|       United States|            Austria|   63|\n",
      "|           Australia|      United States|  329|\n",
      "|       United States|        New Zealand|   74|\n",
      "|       United States|           Suriname|   34|\n",
      "|       United States|           Malaysia|    3|\n",
      "|       United States|             Guyana|   63|\n",
      "|              Taiwan|      United States|  266|\n",
      "|            Portugal|      United States|  127|\n",
      "|             Bolivia|      United States|   30|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.repartition(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "b2fbffaf-64ac-4cc6-ad64-85da02b05d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0734b9-f104-4993-8058-8aa6848c18e7",
   "metadata": {},
   "source": [
    "---\n",
    "**Collecting Rows to the Driver:** \\\n",
    "As discussed in previous chapters, Spark maintains the state of the cluster in the driver.Collect some of your data to the driver in order to manipulate it on local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "c42724b5-526d-48f4-a384-37a19f06fddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|   15|\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|            Ireland|  344|\n",
      "|            Egypt|      United States|   15|\n",
      "|    United States|              India|   62|\n",
      "+-----------------+-------------------+-----+\n",
      "\n",
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|United States    |Romania            |15   |\n",
      "|United States    |Croatia            |1    |\n",
      "|United States    |Ireland            |344  |\n",
      "|Egypt            |United States      |15   |\n",
      "|United States    |India              |62   |\n",
      "+-----------------+-------------------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Romania', count=15),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Croatia', count=1),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Ireland', count=344),\n",
       " Row(DEST_COUNTRY_NAME='Egypt', ORIGIN_COUNTRY_NAME='United States', count=15),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='India', count=62)]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collectDF = df.limit(5)\n",
    "collectDF.take(5) # take works with an Integer count\n",
    "collectDF.show() # this prints it out nicely\n",
    "collectDF.show(5, False)\n",
    "collectDF.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b4410d-d97f-4d74-82f2-13313b4a6231",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
