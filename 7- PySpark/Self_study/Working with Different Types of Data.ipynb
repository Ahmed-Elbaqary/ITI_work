{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d48dd31-0520-4107-9ff0-b91ae5fed022",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ef4b85c-fdde-46a9-9053-7668fc14b51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0351063-b1fe-4b4b-a035-6d5dd0a9ae2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198c5a86-75c5-4019-8112-8b8af7bf2181",
   "metadata": {},
   "source": [
    "---\n",
    "**Booleans:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "865bb480-33ff-44f4-bce4-4ec7dd5d96e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- InvoiceDate: string (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      " |-- CustomerID: double (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format('csv')\\\n",
    ".option('header', 'true')\\\n",
    ".option('inferSchema', 'true')\\\n",
    ".load('Book_Exercises/data/csv/2012-12-01.txt')\n",
    "df.printSchema()\n",
    "df.createOrReplaceTempView(\"dfTable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec03aaf-d476-4f52-93d0-ee45b845acd7",
   "metadata": {},
   "source": [
    "---\n",
    "**Working with Booleans**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d9b464c-8ec4-4855-b01f-32212bed87d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------------------+\n",
      "|InvoiceNo|Description                  |\n",
      "+---------+-----------------------------+\n",
      "|536366   |HAND WARMER UNION JACK       |\n",
      "|536366   |HAND WARMER RED POLKA DOT    |\n",
      "|536367   |ASSORTED COLOUR BIRD ORNAMENT|\n",
      "|536367   |POPPY'S PLAYHOUSE BEDROOM    |\n",
      "|536367   |POPPY'S PLAYHOUSE KITCHEN    |\n",
      "+---------+-----------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df.where(col(\"InvoiceNo\") != 536365)\\\n",
    ".select(\"InvoiceNo\", \"Description\")\\\n",
    ".show(5, False)\n",
    "\n",
    "# df.where(\"InvoiceNo <> 536365\").show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc4acf56-a399-411b-a43f-3d8433fcd875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|unitPrice|\n",
      "+---------+\n",
      "|   569.77|\n",
      "|   607.49|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import instr\n",
    "\n",
    "priceFilter = col(\"UnitPrice\") > 600\n",
    "descripFilter = instr(df.Description, \"POSTAGE\") >= 1\n",
    "\n",
    "df.where(df.StockCode.isin(\"DOT\"))\\\n",
    ".where(priceFilter | descripFilter)\\\n",
    ".select(\"unitPrice\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0bc8ce38-4c06-4621-bc25-9ed8a24de995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|unitPrice|isExpensive|\n",
      "+---------+-----------+\n",
      "|   569.77|       true|\n",
      "|   607.49|       true|\n",
      "+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import instr\n",
    "\n",
    "DOTCodeFilter = col(\"StockCode\") == \"DOT\"\n",
    "priceFilter = col(\"UnitPrice\") > 600\n",
    "descripFilter = instr(col(\"Description\"), \"POSTAGE\") >= 1\n",
    "\n",
    "df.withColumn(\"isExpensive\", DOTCodeFilter & (priceFilter | descripFilter))\\\n",
    ".where(\"isExpensive\")\\\n",
    ".select(\"unitPrice\", \"isExpensive\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50e53e05-5ffa-4bc0-8098-417696e93f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------+\n",
      "|   Description|UnitPrice|\n",
      "+--------------+---------+\n",
      "|DOTCOM POSTAGE|   569.77|\n",
      "|DOTCOM POSTAGE|   607.49|\n",
      "+--------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "\n",
    "df.withColumn(\"isExpensive\", expr(\"NOT UnitPrice <= 250\"))\\\n",
    ".where(\"isExpensive\")\\\n",
    ".select(\"Description\", \"UnitPrice\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7203d5-1529-42bb-ad53-c9f830303b38",
   "metadata": {},
   "source": [
    "---\n",
    "**Working with Numbers:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "91f1224c-d60e-4104-b048-55c9a3e2e45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n",
      "|CustomerId|      realQuantity|\n",
      "+----------+------------------+\n",
      "|   17850.0|239.08999999999997|\n",
      "|   17850.0|          418.7156|\n",
      "+----------+------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr, pow\n",
    "fabricatedQuantity = pow(col(\"Quantity\") * col(\"UnitPrice\"), 2) + 5\n",
    "df.select(expr(\"CustomerId\"), fabricatedQuantity.alias(\"realQuantity\")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15bae178-21ab-44c7-99e5-dd60aab4a648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n",
      "|CustomerId|      realQuantity|\n",
      "+----------+------------------+\n",
      "|   17850.0|239.08999999999997|\n",
      "|   17850.0|          418.7156|\n",
      "+----------+------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# USING selectExpr\n",
    "df.selectExpr(\n",
    "\"CustomerId\",\n",
    "\"(POWER((Quantity * UnitPrice), 2.0) + 5) as realQuantity\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f9a3b4f3-3d8d-44db-a6b9-270b3b7441c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+\n",
      "|round(2.5, 0)|bround(2.5, 0)|\n",
      "+-------------+--------------+\n",
      "|          3.0|           2.0|\n",
      "|          3.0|           2.0|\n",
      "+-------------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ROUNDING and BROUNDING\n",
    "#if we are inbetween:\n",
    "#    round ==> round up\n",
    "#    bround => round down\n",
    "from pyspark.sql.functions import lit, round, bround\n",
    "df.select(round(lit(\"2.5\")), bround(lit(\"2.5\"))).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "725ea623-912e-4f60-acee-41067b0de7f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.04112314436835551"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the correlation between two columns\n",
    "from pyspark.sql.functions import corr\n",
    "df.stat.corr('Quantity', 'UnitPrice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d6b4bed7-4c23-4bf2-bae2-b352c6c35b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+--------------------+------------------+-------------------+------------------+------------------+--------------+\n",
      "|summary|        InvoiceNo|         StockCode|         Description|          Quantity|        InvoiceDate|         UnitPrice|        CustomerID|       Country|\n",
      "+-------+-----------------+------------------+--------------------+------------------+-------------------+------------------+------------------+--------------+\n",
      "|  count|             3108|              3108|                3098|              3108|               3108|              3108|              1968|          3108|\n",
      "|   mean| 536516.684944841|27834.304044117645|                null| 8.627413127413128|               null| 4.151946589446603|15661.388719512195|          null|\n",
      "| stddev|72.89447869788873|17407.897548583845|                null|26.371821677029203|               null|15.638659854603892|1854.4496996893627|          null|\n",
      "|    min|           536365|             10002| 4 PURPLE FLOCK D...|               -24|2010-12-01 08:26:00|               0.0|           12431.0|     Australia|\n",
      "|    max|          C536548|              POST|ZINC WILLIE WINKI...|               600|2010-12-01 17:35:00|            607.49|           18229.0|United Kingdom|\n",
      "+-------+-----------------+------------------+--------------------+------------------+-------------------+------------------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Summary of numeric columns:\n",
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f41808a-77f8-4f88-8dc6-16e1191ad97f",
   "metadata": {},
   "source": [
    "There are a number of statistical functions available in the StatFunctions Package (accessible\n",
    "using stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fb7d0c21-7a5e-47ea-b034-da04a3189262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.65, 2.51, 4.21, 5.95]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Approximate quantile of a column\n",
    "colName = \"UnitPrice\"\n",
    "quantileProbs = [0.5]\n",
    "relError = 0.05\n",
    "df.stat.approxQuantile(\"UnitPrice\", [0.25, 0.5, 0.75, 0.9], 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f69703e9-0f50-4e88-8590-9242dbb95ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "| StockCode_freqItems|  Quantity_freqItems|\n",
      "+--------------------+--------------------+\n",
      "|[90214E, 20728, 2...|[200, 128, 23, 32...|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#df.stat.crosstab(\"StockCode\", \"Quantity\").show()\n",
    "df.stat.freqItems([\"StockCode\", \"Quantity\"]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef349d47-479c-4058-931e-1647537af9bb",
   "metadata": {},
   "source": [
    "**we can also add a unique ID to each row by using the function\n",
    "monotonically_increasing_id. This function generates a unique value for each row, starting\n",
    "with 0:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0d279ffd-c8b0-417e-b5aa-08fe8280913b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+\n",
      "|monotonically_increasing_id()|\n",
      "+-----------------------------+\n",
      "|                            0|\n",
      "|                            1|\n",
      "+-----------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "df.select(monotonically_increasing_id()).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8432cae4-664f-4e59-8163-880cf1b83748",
   "metadata": {},
   "source": [
    "---\n",
    "**Working with Strings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c4b5b49b-6dc7-47fd-a862-de9283a97149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|initcap(Description)|\n",
      "+--------------------+\n",
      "|White Hanging Hea...|\n",
      "| White Metal Lantern|\n",
      "|Cream Cupid Heart...|\n",
      "|Knitted Union Fla...|\n",
      "|Red Woolly Hottie...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# initcap function will capitalize every word in a given string when that word is separated from another by a space\n",
    "from pyspark.sql.functions import initcap\n",
    "df.select(initcap(col(\"Description\"))).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aaea17a9-b9fc-408f-bbd3-5a7fb328fa78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------------------+\n",
      "|         Description|  lower(Description)|upper(lower(Description))|\n",
      "+--------------------+--------------------+-------------------------+\n",
      "|WHITE HANGING HEA...|white hanging hea...|     WHITE HANGING HEA...|\n",
      "| WHITE METAL LANTERN| white metal lantern|      WHITE METAL LANTERN|\n",
      "+--------------------+--------------------+-------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# UPPER and lower case:\n",
    "from pyspark.sql.functions import lower, upper\n",
    "df.select(col(\"Description\"),\n",
    "lower(col(\"Description\")),\n",
    "upper(lower(col(\"Description\")))).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "679ae848-b992-4f11-b0d9-cec03d7e0db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+-----+---+----------+\n",
      "| ltrim| rtrim| trim| lp|        rp|\n",
      "+------+------+-----+---+----------+\n",
      "|HELLO | HELLO|HELLO|HEL|HELLO     |\n",
      "|HELLO | HELLO|HELLO|HEL|HELLO     |\n",
      "+------+------+-----+---+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit, ltrim, rtrim, rpad, lpad, trim\n",
    "df.select(\n",
    "ltrim(lit(\" HELLO \")).alias(\"ltrim\"),\n",
    "rtrim(lit(\" HELLO \")).alias(\"rtrim\"),\n",
    "trim(lit(\" HELLO \")).alias(\"trim\"),\n",
    "lpad(lit(\"HELLO\"), 3, \" \").alias(\"lp\"),\n",
    "rpad(lit(\"HELLO\"), 10, \" \").alias(\"rp\")).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a7f285-914b-475b-98eb-5d12628159de",
   "metadata": {},
   "source": [
    "___\n",
    "**Working with dates and times**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ce354e6-c80c-45c4-9104-8b519a532949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = false)\n",
      " |-- Today: date (nullable = false)\n",
      " |-- Now: timestamp (nullable = false)\n",
      "\n",
      "+---+----------+--------------------+\n",
      "| id|     Today|                 Now|\n",
      "+---+----------+--------------------+\n",
      "|  0|2021-10-24|2021-10-24 16:24:...|\n",
      "|  1|2021-10-24|2021-10-24 16:24:...|\n",
      "|  2|2021-10-24|2021-10-24 16:24:...|\n",
      "|  3|2021-10-24|2021-10-24 16:24:...|\n",
      "|  4|2021-10-24|2021-10-24 16:24:...|\n",
      "|  5|2021-10-24|2021-10-24 16:24:...|\n",
      "|  6|2021-10-24|2021-10-24 16:24:...|\n",
      "|  7|2021-10-24|2021-10-24 16:24:...|\n",
      "|  8|2021-10-24|2021-10-24 16:24:...|\n",
      "|  9|2021-10-24|2021-10-24 16:24:...|\n",
      "+---+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import current_date, current_timestamp\n",
    "dataDF = spark.range(10)\\\n",
    ".withColumn('Today', current_date())\\\n",
    ".withColumn('Now', current_timestamp())\n",
    "\n",
    "dataDF.printSchema()\n",
    "dataDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66b43168-3103-47cd-a9c6-104c23680bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+\n",
      "|date_sub(Today, 5)|date_add(Today, 5)|\n",
      "+------------------+------------------+\n",
      "|        2021-10-19|        2021-10-29|\n",
      "|        2021-10-19|        2021-10-29|\n",
      "+------------------+------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Adding and subtracting dates:\n",
    "from pyspark.sql.functions import date_add, date_sub\n",
    "dataDF.select(date_sub(col('Today'), 5), date_add(col('Today'), 5)).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "293d7f24-74f5-41fc-b39d-3f2f0d447f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|datediff(week_ago, today)|\n",
      "+-------------------------+\n",
      "|                       -7|\n",
      "+-------------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "+--------------------------------+\n",
      "|months_between(start, end, true)|\n",
      "+--------------------------------+\n",
      "|                    -16.67741935|\n",
      "+--------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The difference between two dates in days using datediff\n",
    "# The months_between gives the number of monthes between two dates\n",
    "\n",
    "from pyspark.sql.functions import lit, datediff, months_between, to_date\n",
    "dataDF.withColumn(\"week_ago\", date_sub(col(\"today\"), 7))\\\n",
    ".select(datediff(col(\"week_ago\"), col(\"today\"))).show(1)\n",
    "dataDF.select(\n",
    "to_date(lit(\"2016-01-01\")).alias(\"start\"),\n",
    "to_date(lit(\"2017-05-22\")).alias(\"end\"))\\\n",
    ".select(months_between(col(\"start\"), col(\"end\"))).show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2314c1af-ab98-402e-8348-31b156dcf770",
   "metadata": {},
   "source": [
    "___\n",
    "**Dealing with null data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6c0f0ba-c8eb-43e9-8e55-74e7ddc94e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|2010-12-01 08:26:00|     2.55|   17850.0|United Kingdom|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop\n",
    "df.na.drop(\"all\", subset=[\"StockCode\", \"InvoiceNo\"]).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e90ca8f7-fa15-440a-af8f-2ba7a3639c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|2010-12-01 08:26:00|     2.55|   17850.0|United Kingdom|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fill string columns with a specific value\n",
    "df.na.fill(\"all\", subset=[\"StockCode\", \"InvoiceNo\"]).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "413c3558-b77a-47fa-b69d-ba72246484c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|2010-12-01 08:26:00|     2.55|   17850.0|United Kingdom|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fill_cols_vals = {\"StockCode\": 5, \"Description\" : \"No Value\"}\n",
    "df.na.fill(fill_cols_vals).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "235b7fe7-c0f3-442f-b88d-026294626d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|2010-12-01 08:26:00|     2.55|   17850.0|United Kingdom|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Replace values with something else\n",
    "df.na.replace([\"\"], [\"UNKNOWN\"], \"Description\").show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9aaf980-6c15-492d-944f-d72cfda6f282",
   "metadata": {},
   "source": [
    "---\n",
    "**WORKING WITH COMPLEX TYPES**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7512f8c0-a777-4f3d-887a-772b9807ea8b",
   "metadata": {},
   "source": [
    "* **Structs:** \\\n",
    "You can think of structs as DataFrames within DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31b73030-ec4a-45de-b93e-7a994706c7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import struct\n",
    "complexDF = df.select(struct(\"Description\", \"InvoiceNo\").alias(\"complex\"))\n",
    "complexDF.createOrReplaceTempView(\"complexDF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe65679-78a1-41f5-b918-f58e17e59f30",
   "metadata": {},
   "source": [
    "We now have a DataFrame with a column complex. We can query it just as we might another\n",
    "DataFrame, the only difference is that we use a dot syntax to do so, or the column method\n",
    "getField:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "efbcc8d4-4858-4690-a0ea-9854e7790689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|         Description|\n",
      "+--------------------+\n",
      "|WHITE HANGING HEA...|\n",
      "| WHITE METAL LANTERN|\n",
      "+--------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+--------------------+\n",
      "| complex.Description|\n",
      "+--------------------+\n",
      "|WHITE HANGING HEA...|\n",
      "| WHITE METAL LANTERN|\n",
      "+--------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+--------------------+---------+\n",
      "|         Description|InvoiceNo|\n",
      "+--------------------+---------+\n",
      "|WHITE HANGING HEA...|   536365|\n",
      "| WHITE METAL LANTERN|   536365|\n",
      "+--------------------+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "complexDF.select(\"complex.Description\").show(2)\n",
    "complexDF.select(col(\"complex\").getField(\"Description\")).show(2)\n",
    "complexDF.select(\"complex.*\").show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e3f698-6893-4735-9e2c-e8535bef3d99",
   "metadata": {},
   "source": [
    "___\n",
    "* **ARRAYS** \n",
    "\n",
    "**1) Split:**\n",
    "Splitting words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6c09623e-69e2-4c80-a76d-1b3ea3b621ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|split(Description,  , -1)|\n",
      "+-------------------------+\n",
      "|     [WHITE, HANGING, ...|\n",
      "|     [WHITE, METAL, LA...|\n",
      "+-------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import split\n",
    "df.select(split(col('Description'), \" \")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "48599631-fa50-44d1-9cac-7ad3d8a6c6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+\n",
      "|array_col[0]|array_col[1]|\n",
      "+------------+------------+\n",
      "|       WHITE|     HANGING|\n",
      "|       WHITE|       METAL|\n",
      "+------------+------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(split(col('Description'), \" \").alias(\"array_col\"))\\\n",
    "         .selectExpr(\"array_col[0]\", \"array_col[1]\").show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213df3d1-f70d-4d08-ba71-995c63418db3",
   "metadata": {},
   "source": [
    "**2) Array length:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "073adee8-b328-44be-8760-cb2612de3238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|array_length|\n",
      "+------------+\n",
      "|           5|\n",
      "|           3|\n",
      "+------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import size\n",
    "splits = split(col('Description'), ' ')\n",
    "df.select(size(splits).alias('array_length')).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a92ae9-04d3-4c7c-9368-0cfc10e03ff2",
   "metadata": {},
   "source": [
    "**3) array_contains:**\n",
    "We can also see whether this array contains a value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c843d476-b7bc-489f-9358-20092e56009a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|Contains|\n",
      "+--------+\n",
      "|    true|\n",
      "|    true|\n",
      "+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# array_contains(column, word to search)\n",
    "\n",
    "from pyspark.sql.functions import array_contains\n",
    "splits = split(col(\"Description\"), \" \")\n",
    "df.select(array_contains(splits, \"WHITE\").alias('Contains')).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06af5a4-5dda-4cea-8a06-cf370049f39f",
   "metadata": {},
   "source": [
    "**3) explode** \n",
    "The explode function takes a column that consists of arrays and creates one row (with the rest of\n",
    "the values duplicated) per value in the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6bdad3e9-dcda-4b51-9658-691ebcff9e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------+\n",
      "|         Description|InvoiceNo|exploded|\n",
      "+--------------------+---------+--------+\n",
      "|WHITE HANGING HEA...|   536365|   WHITE|\n",
      "|WHITE HANGING HEA...|   536365| HANGING|\n",
      "|WHITE HANGING HEA...|   536365|   HEART|\n",
      "|WHITE HANGING HEA...|   536365| T-LIGHT|\n",
      "|WHITE HANGING HEA...|   536365|  HOLDER|\n",
      "| WHITE METAL LANTERN|   536365|   WHITE|\n",
      "| WHITE METAL LANTERN|   536365|   METAL|\n",
      "| WHITE METAL LANTERN|   536365| LANTERN|\n",
      "|CREAM CUPID HEART...|   536365|   CREAM|\n",
      "|CREAM CUPID HEART...|   536365|   CUPID|\n",
      "+--------------------+---------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import split, explode\n",
    "df.withColumn(\"splitted\", split(col(\"Description\"), \" \"))\\\n",
    ".withColumn(\"exploded\", explode(col(\"splitted\")))\\\n",
    ".select(\"Description\", \"InvoiceNo\", \"exploded\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0303c8e2-d9bc-4fce-bcfd-aafe886085c1",
   "metadata": {},
   "source": [
    "**4) Maps**\n",
    "Maps are created by using the map function and key-value pairs of columns. You then can select\n",
    "them just like you might select from an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a69d8f4c-d9ce-460d-a946-42930d528383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|         Complex_map|\n",
      "+--------------------+\n",
      "|{536365 -> WHITE ...|\n",
      "|{536365 -> WHITE ...|\n",
      "+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import create_map\n",
    "df.select(create_map(col(\"InvoiceNo\"), col(\"Description\"))\\\n",
    "          .alias(\"Complex_map\")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8327f316-edc1-4032-95b9-cd38c4b42c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "| Complex_map[536365]|\n",
      "+--------------------+\n",
      "|WHITE HANGING HEA...|\n",
      "| WHITE METAL LANTERN|\n",
      "+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(create_map(col(\"InvoiceNo\"), col(\"Description\"))\\\n",
    "          .alias(\"Complex_map\"))\\\n",
    "            .selectExpr(\"Complex_map['536365']\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b18410db-90f2-4427-a341-749d07bebe2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|   key|               value|\n",
      "+------+--------------------+\n",
      "|536365|WHITE HANGING HEA...|\n",
      "|536365| WHITE METAL LANTERN|\n",
      "+------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# You can also explode map types, which will turn them into columns:\n",
    "df.select(create_map(col(\"InvoiceNo\"), col(\"Description\"))\\\n",
    "          .alias(\"Complex_map\"))\\\n",
    ".selectExpr(\"explode(Complex_map)\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cf48f9-1855-40ac-99ca-9c5ba9e547ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
